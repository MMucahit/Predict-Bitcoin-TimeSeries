{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>Closing Price (USD)</th>\n",
       "      <th>24h Open (USD)</th>\n",
       "      <th>24h High (USD)</th>\n",
       "      <th>24h Low (USD)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>BTC</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>124.30466</td>\n",
       "      <td>124.75166</td>\n",
       "      <td>122.56349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>BTC</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>125.75850</td>\n",
       "      <td>123.63383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>BTC</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>125.66566</td>\n",
       "      <td>83.32833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>BTC</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>118.67500</td>\n",
       "      <td>107.05816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>BTC</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>121.93633</td>\n",
       "      <td>118.00566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Currency  Closing Price (USD)  24h Open (USD)  24h High (USD)  \\\n",
       "Date                                                                       \n",
       "2013-10-01      BTC            123.65499       124.30466       124.75166   \n",
       "2013-10-02      BTC            125.45500       123.65499       125.75850   \n",
       "2013-10-03      BTC            108.58483       125.45500       125.66566   \n",
       "2013-10-04      BTC            118.67466       108.58483       118.67500   \n",
       "2013-10-05      BTC            121.33866       118.67466       121.93633   \n",
       "\n",
       "            24h Low (USD)  \n",
       "Date                       \n",
       "2013-10-01      122.56349  \n",
       "2013-10-02      123.63383  \n",
       "2013-10-03       83.32833  \n",
       "2013-10-04      107.05816  \n",
       "2013-10-05      118.00566  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\",parse_dates=[\"Date\"],index_col=[\"Date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2787 entries, 2013-10-01 to 2021-05-18\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Currency             2787 non-null   object \n",
      " 1   Closing Price (USD)  2787 non-null   float64\n",
      " 2   24h Open (USD)       2787 non-null   float64\n",
      " 3   24h High (USD)       2787 non-null   float64\n",
      " 4   24h Low (USD)        2787 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 130.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price\n",
       "Date                 \n",
       "2013-10-01  123.65499\n",
       "2013-10-02  125.45500\n",
       "2013-10-03  108.58483\n",
       "2013-10-04  118.67466\n",
       "2013-10-05  121.33866"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices = pd.DataFrame(df[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\":\"Price\"})\n",
    "bitcoin_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['2013-10-01T00:00:00.000000000', '2013-10-02T00:00:00.000000000',\n",
       "        '2013-10-03T00:00:00.000000000', ...,\n",
       "        '2021-05-16T00:00:00.000000000', '2021-05-17T00:00:00.000000000',\n",
       "        '2021-05-18T00:00:00.000000000'], dtype='datetime64[ns]'),\n",
       " array([  123.65499   ,   125.455     ,   108.58483   , ...,\n",
       "        47885.62525472, 45604.61575361, 43144.47129086]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = bitcoin_prices.index.to_numpy()\n",
    "prices    = bitcoin_prices[\"Price\"].to_numpy()\n",
    "\n",
    "timesteps, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_prices[\"Price\"] = bitcoin_prices[\"Price\"]/bitcoin_prices[\"Price\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2013-10-01    0.001952\n",
       "2013-10-02    0.001980\n",
       "2013-10-03    0.001714\n",
       "2013-10-04    0.001873\n",
       "2013-10-05    0.001915\n",
       "                ...   \n",
       "2021-05-14    0.785583\n",
       "2021-05-15    0.789822\n",
       "2021-05-16    0.755928\n",
       "2021-05-17    0.719920\n",
       "2021-05-18    0.681084\n",
       "Name: Price, Length: 2787, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 1\n",
    "WINDOW_SIZE = 7\n",
    "\n",
    "bitcoin_prices_windowed = bitcoin_prices.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>0.001952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price   Price+1   Price+2   Price+3   Price+4  Price+5  \\\n",
       "Date                                                                    \n",
       "2013-10-01  0.001952       NaN       NaN       NaN       NaN      NaN   \n",
       "2013-10-02  0.001980  0.001952       NaN       NaN       NaN      NaN   \n",
       "2013-10-03  0.001714  0.001980  0.001952       NaN       NaN      NaN   \n",
       "2013-10-04  0.001873  0.001714  0.001980  0.001952       NaN      NaN   \n",
       "2013-10-05  0.001915  0.001873  0.001714  0.001980  0.001952      NaN   \n",
       "\n",
       "            Price+6  Price+7  \n",
       "Date                          \n",
       "2013-10-01      NaN      NaN  \n",
       "2013-10-02      NaN      NaN  \n",
       "2013-10-03      NaN      NaN  \n",
       "2013-10-04      NaN      NaN  \n",
       "2013-10-05      NaN      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(WINDOW_SIZE):\n",
    "\n",
    "    bitcoin_prices_windowed[f\"Price+{i+1}\"] = bitcoin_prices_windowed[\"Price\"].shift(periods=i+1)\n",
    "\n",
    "bitcoin_prices_windowed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-08</th>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.001952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-09</th>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.001980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-10</th>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-11</th>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-12</th>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price+1   Price+2   Price+3   Price+4   Price+5   Price+6  \\\n",
       "Date                                                                     \n",
       "2013-10-08  0.001923  0.001905  0.001915  0.001873  0.001714  0.001980   \n",
       "2013-10-09  0.001942  0.001923  0.001905  0.001915  0.001873  0.001714   \n",
       "2013-10-10  0.001958  0.001942  0.001923  0.001905  0.001915  0.001873   \n",
       "2013-10-11  0.001988  0.001958  0.001942  0.001923  0.001905  0.001915   \n",
       "2013-10-12  0.001978  0.001988  0.001958  0.001942  0.001923  0.001905   \n",
       "\n",
       "             Price+7  \n",
       "Date                  \n",
       "2013-10-08  0.001952  \n",
       "2013-10-09  0.001980  \n",
       "2013-10-10  0.001714  \n",
       "2013-10-11  0.001873  \n",
       "2013-10-12  0.001915  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "X = bitcoin_prices_windowed.dropna().drop(\"Price\",axis=1).astype(np.float32)\n",
    "y = bitcoin_prices_windowed.dropna()[\"Price\"].astype(np.float32)\n",
    "\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2224, 2224, 556, 556)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_size = int(0.8 * len(X))\n",
    "\n",
    "X_train, y_train = X[:split_size], y[:split_size]\n",
    "X_test, y_test   = X[split_size:], y[split_size:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-08</th>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.001952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-09</th>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.001980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-10</th>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-11</th>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-12</th>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05</th>\n",
       "      <td>0.145270</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.145195</td>\n",
       "      <td>0.144150</td>\n",
       "      <td>0.145643</td>\n",
       "      <td>0.149269</td>\n",
       "      <td>0.149309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06</th>\n",
       "      <td>0.147910</td>\n",
       "      <td>0.145270</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.145195</td>\n",
       "      <td>0.144150</td>\n",
       "      <td>0.145643</td>\n",
       "      <td>0.149269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07</th>\n",
       "      <td>0.147231</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>0.145270</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.145195</td>\n",
       "      <td>0.144150</td>\n",
       "      <td>0.145643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08</th>\n",
       "      <td>0.147375</td>\n",
       "      <td>0.147231</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>0.145270</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.145195</td>\n",
       "      <td>0.144150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09</th>\n",
       "      <td>0.145650</td>\n",
       "      <td>0.147375</td>\n",
       "      <td>0.147231</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>0.145270</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.145195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2224 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price+1   Price+2   Price+3   Price+4   Price+5   Price+6  \\\n",
       "Date                                                                     \n",
       "2013-10-08  0.001923  0.001905  0.001915  0.001873  0.001714  0.001980   \n",
       "2013-10-09  0.001942  0.001923  0.001905  0.001915  0.001873  0.001714   \n",
       "2013-10-10  0.001958  0.001942  0.001923  0.001905  0.001915  0.001873   \n",
       "2013-10-11  0.001988  0.001958  0.001942  0.001923  0.001905  0.001915   \n",
       "2013-10-12  0.001978  0.001988  0.001958  0.001942  0.001923  0.001905   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2019-11-05  0.145270  0.146667  0.145195  0.144150  0.145643  0.149269   \n",
       "2019-11-06  0.147910  0.145270  0.146667  0.145195  0.144150  0.145643   \n",
       "2019-11-07  0.147231  0.147910  0.145270  0.146667  0.145195  0.144150   \n",
       "2019-11-08  0.147375  0.147231  0.147910  0.145270  0.146667  0.145195   \n",
       "2019-11-09  0.145650  0.147375  0.147231  0.147910  0.145270  0.146667   \n",
       "\n",
       "             Price+7  \n",
       "Date                  \n",
       "2013-10-08  0.001952  \n",
       "2013-10-09  0.001980  \n",
       "2013-10-10  0.001714  \n",
       "2013-10-11  0.001873  \n",
       "2013-10-12  0.001915  \n",
       "...              ...  \n",
       "2019-11-05  0.149309  \n",
       "2019-11-06  0.149269  \n",
       "2019-11-07  0.145643  \n",
       "2019-11-08  0.144150  \n",
       "2019-11-09  0.145195  \n",
       "\n",
       "[2224 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214aa865c60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(WINDOW_SIZE,),name=\"input_layer\")\n",
    "\n",
    "x = tf.keras.layers.Dense(128,kernel_initializer=\"he_normal\",activation=\"relu\")(inputs)\n",
    "\n",
    "x = tf.keras.layers.Dense(128,kernel_initializer=\"he_normal\",activation=\"relu\")(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(HORIZON,activation=\"linear\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs,name=\"model\")\n",
    "\n",
    "model.compile(\n",
    "    loss = \"mae\",\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=128,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.011410816572606564, 0.011410816572606564]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>Closing Price (USD)</th>\n",
       "      <th>24h Open (USD)</th>\n",
       "      <th>24h High (USD)</th>\n",
       "      <th>24h Low (USD)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>BTC</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>124.30466</td>\n",
       "      <td>124.75166</td>\n",
       "      <td>122.56349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>BTC</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>125.75850</td>\n",
       "      <td>123.63383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>BTC</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>125.66566</td>\n",
       "      <td>83.32833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>BTC</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>118.67500</td>\n",
       "      <td>107.05816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>BTC</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>121.93633</td>\n",
       "      <td>118.00566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Currency  Closing Price (USD)  24h Open (USD)  24h High (USD)  \\\n",
       "Date                                                                       \n",
       "2013-10-01      BTC            123.65499       124.30466       124.75166   \n",
       "2013-10-02      BTC            125.45500       123.65499       125.75850   \n",
       "2013-10-03      BTC            108.58483       125.45500       125.66566   \n",
       "2013-10-04      BTC            118.67466       108.58483       118.67500   \n",
       "2013-10-05      BTC            121.33866       118.67466       121.93633   \n",
       "\n",
       "            24h Low (USD)  \n",
       "Date                       \n",
       "2013-10-01      122.56349  \n",
       "2013-10-02      123.63383  \n",
       "2013-10-03       83.32833  \n",
       "2013-10-04      107.05816  \n",
       "2013-10-05      118.00566  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\",parse_dates=[\"Date\"],index_col=[\"Date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.654990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.584830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.674660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.338660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>49764.132082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-15</th>\n",
       "      <td>50032.693137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-16</th>\n",
       "      <td>47885.625255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-17</th>\n",
       "      <td>45604.615754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18</th>\n",
       "      <td>43144.471291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2787 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Price\n",
       "Date                    \n",
       "2013-10-01    123.654990\n",
       "2013-10-02    125.455000\n",
       "2013-10-03    108.584830\n",
       "2013-10-04    118.674660\n",
       "2013-10-05    121.338660\n",
       "...                  ...\n",
       "2021-05-14  49764.132082\n",
       "2021-05-15  50032.693137\n",
       "2021-05-16  47885.625255\n",
       "2021-05-17  45604.615754\n",
       "2021-05-18  43144.471291\n",
       "\n",
       "[2787 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices = pd.DataFrame(df[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\":\"Price\"})\n",
    "bitcoin_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 7\n",
    "HORIZON = 1\n",
    "\n",
    "bitcoin_prices_windowed = bitcoin_prices.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price    Price+1    Price+2    Price+3    Price+4  Price+5  \\\n",
       "Date                                                                         \n",
       "2013-10-01  123.65499        NaN        NaN        NaN        NaN      NaN   \n",
       "2013-10-02  125.45500  123.65499        NaN        NaN        NaN      NaN   \n",
       "2013-10-03  108.58483  125.45500  123.65499        NaN        NaN      NaN   \n",
       "2013-10-04  118.67466  108.58483  125.45500  123.65499        NaN      NaN   \n",
       "2013-10-05  121.33866  118.67466  108.58483  125.45500  123.65499      NaN   \n",
       "\n",
       "            Price+6  Price+7  \n",
       "Date                          \n",
       "2013-10-01      NaN      NaN  \n",
       "2013-10-02      NaN      NaN  \n",
       "2013-10-03      NaN      NaN  \n",
       "2013-10-04      NaN      NaN  \n",
       "2013-10-05      NaN      NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(WINDOW_SIZE):\n",
    "    bitcoin_prices_windowed[f\"Price+{i+1}\"] = bitcoin_prices_windowed[\"Price\"].shift(periods=i+1)\n",
    "\n",
    "bitcoin_prices_windowed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bitcoin_prices_windowed.dropna().drop([\"Price\"],axis=1).to_numpy()\n",
    "\n",
    "y = bitcoin_prices_windowed.dropna()[\"Price\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf.data.Dataset.from_tensor_slices(X)\n",
    "labels   = tf.data.Dataset.from_tensor_slices(y)\n",
    "\n",
    "data = tf.data.Dataset.zip((features,labels))\n",
    "\n",
    "data = data.batch(1024).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 595.5912 - mae: 595.5912\n",
      "Epoch 1: mae improved from inf to 3326.40723, saving model to D:/Me-ScriptsnShit/TensorFlow/Time Series\\\n",
      "3/3 [==============================] - 1s 264ms/step - loss: 3326.4072 - mae: 3326.4072\n",
      "Epoch 2/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 40.3196 - mae: 40.3196\n",
      "Epoch 2: mae did not improve from 3326.40723\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3743.9121 - mae: 3743.9121\n",
      "Epoch 3/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 246.6157 - mae: 246.6157\n",
      "Epoch 3: mae improved from 3326.40723 to 2848.26465, saving model to D:/Me-ScriptsnShit/TensorFlow/Time Series\\\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 2848.2646 - mae: 2848.2646\n",
      "Epoch 4/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 77.1493 - mae: 77.1493\n",
      "Epoch 4: mae improved from 2848.26465 to 1049.62109, saving model to D:/Me-ScriptsnShit/TensorFlow/Time Series\\\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 1049.6211 - mae: 1049.6211\n",
      "Epoch 5/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 86.7259 - mae: 86.7259\n",
      "Epoch 5: mae did not improve from 1049.62109\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1174.2668 - mae: 1174.2668\n",
      "Epoch 6/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 22.7434 - mae: 22.7434\n",
      "Epoch 6: mae did not improve from 1049.62109\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1053.0115 - mae: 1053.0115\n",
      "Epoch 7/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 67.7247 - mae: 67.7247\n",
      "Epoch 7: mae improved from 1049.62109 to 573.96106, saving model to D:/Me-ScriptsnShit/TensorFlow/Time Series\\\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 573.9610 - mae: 573.9611\n",
      "Epoch 8/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 32.5671 - mae: 32.5671\n",
      "Epoch 8: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1497.1279 - mae: 1497.1279\n",
      "Epoch 9/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 93.5202 - mae: 93.5202\n",
      "Epoch 9: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 948.9164 - mae: 948.9164\n",
      "Epoch 10/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21.1693 - mae: 21.1693\n",
      "Epoch 10: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1370.2931 - mae: 1370.2931\n",
      "Epoch 11/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 97.0365 - mae: 97.0365\n",
      "Epoch 11: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1165.5201 - mae: 1165.5201\n",
      "Epoch 12/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25.7869 - mae: 25.7869\n",
      "Epoch 12: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 938.3220 - mae: 938.3220\n",
      "Epoch 13/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 65.8995 - mae: 65.8995\n",
      "Epoch 13: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 739.2836 - mae: 739.2836\n",
      "Epoch 14/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21.3746 - mae: 21.3746\n",
      "Epoch 14: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1144.5391 - mae: 1144.5391\n",
      "Epoch 15/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 74.9396 - mae: 74.9396\n",
      "Epoch 15: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 742.8768 - mae: 742.8768\n",
      "Epoch 16/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 22.0411 - mae: 22.0411\n",
      "Epoch 16: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1246.9794 - mae: 1246.9794\n",
      "Epoch 17/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 82.8635 - mae: 82.8635\n",
      "Epoch 17: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 922.1187 - mae: 922.1187\n",
      "Epoch 18/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.3236 - mae: 19.3236\n",
      "Epoch 18: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1111.1730 - mae: 1111.1730\n",
      "Epoch 19/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 77.3562 - mae: 77.3562\n",
      "Epoch 19: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 861.6741 - mae: 861.6741\n",
      "Epoch 20/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.2286 - mae: 19.2286\n",
      "Epoch 20: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1088.7006 - mae: 1088.7006\n",
      "Epoch 21/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 74.0685 - mae: 74.0685\n",
      "Epoch 21: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 829.5661 - mae: 829.5661\n",
      "Epoch 22/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.6640 - mae: 19.6640\n",
      "Epoch 22: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1104.8604 - mae: 1104.8604\n",
      "Epoch 23/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 75.0113 - mae: 75.0113\n",
      "Epoch 23: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 802.7335 - mae: 802.7335\n",
      "Epoch 24/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.4397 - mae: 19.4397\n",
      "Epoch 24: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1115.6185 - mae: 1115.6185\n",
      "Epoch 25/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 75.2882 - mae: 75.2882\n",
      "Epoch 25: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 839.3032 - mae: 839.3032\n",
      "Epoch 26/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.4264 - mae: 19.4264\n",
      "Epoch 26: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1092.5033 - mae: 1092.5033\n",
      "Epoch 27/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 74.5517 - mae: 74.5517\n",
      "Epoch 27: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 806.8184 - mae: 806.8184\n",
      "Epoch 28/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.1876 - mae: 19.1876\n",
      "Epoch 28: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1088.0688 - mae: 1088.0688\n",
      "Epoch 29/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 73.4534 - mae: 73.4534\n",
      "Epoch 29: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 814.6699 - mae: 814.6699\n",
      "Epoch 30/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.5799 - mae: 19.5799\n",
      "Epoch 30: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1095.1571 - mae: 1095.1571\n",
      "Epoch 31/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 74.5289 - mae: 74.5289\n",
      "Epoch 31: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 807.4842 - mae: 807.4842\n",
      "Epoch 32/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.0549 - mae: 19.0549\n",
      "Epoch 32: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1075.9249 - mae: 1075.9249\n",
      "Epoch 33/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 72.8774 - mae: 72.8774\n",
      "Epoch 33: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 811.7510 - mae: 811.7510\n",
      "Epoch 34/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.3829 - mae: 19.3829\n",
      "Epoch 34: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1076.9354 - mae: 1076.9354\n",
      "Epoch 35/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 73.2213 - mae: 73.2213\n",
      "Epoch 35: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 791.5618 - mae: 791.5618\n",
      "Epoch 36/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.0654 - mae: 19.0654\n",
      "Epoch 36: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1073.0244 - mae: 1073.0244\n",
      "Epoch 37/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 72.6430 - mae: 72.6430\n",
      "Epoch 37: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 808.5347 - mae: 808.5347\n",
      "Epoch 38/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.2684 - mae: 19.2684\n",
      "Epoch 38: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1065.7538 - mae: 1065.7538\n",
      "Epoch 39/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 72.4999 - mae: 72.4999\n",
      "Epoch 39: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 786.5893 - mae: 786.5893\n",
      "Epoch 40/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.9847 - mae: 18.9847\n",
      "Epoch 40: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1060.2410 - mae: 1060.2410\n",
      "Epoch 41/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 71.8295 - mae: 71.8295\n",
      "Epoch 41: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 797.9551 - mae: 797.9551\n",
      "Epoch 42/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.2515 - mae: 19.2515\n",
      "Epoch 42: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1058.8351 - mae: 1058.8351\n",
      "Epoch 43/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 71.9040 - mae: 71.9040\n",
      "Epoch 43: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 780.3203 - mae: 780.3203\n",
      "Epoch 44/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.9336 - mae: 18.9336\n",
      "Epoch 44: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1050.4054 - mae: 1050.4054\n",
      "Epoch 45/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 71.3294 - mae: 71.3294\n",
      "Epoch 45: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 793.3184 - mae: 793.3184\n",
      "Epoch 46/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.1309 - mae: 19.1309\n",
      "Epoch 46: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1044.0541 - mae: 1044.0541\n",
      "Epoch 47/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 70.8064 - mae: 70.8064\n",
      "Epoch 47: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 766.8069 - mae: 766.8069\n",
      "Epoch 48/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.9595 - mae: 18.9595\n",
      "Epoch 48: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1043.5325 - mae: 1043.5325\n",
      "Epoch 49/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 70.8970 - mae: 70.8970\n",
      "Epoch 49: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 789.2485 - mae: 789.2485\n",
      "Epoch 50/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.0121 - mae: 19.0121\n",
      "Epoch 50: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1027.4414 - mae: 1027.4414\n",
      "Epoch 51/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 69.7920 - mae: 69.7920\n",
      "Epoch 51: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 759.9793 - mae: 759.9793\n",
      "Epoch 52/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.9371 - mae: 18.9371\n",
      "Epoch 52: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1019.2331 - mae: 1019.2331\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 761.3475 - mae: 761.3475\n",
      "Epoch 53: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 761.3475 - mae: 761.3475\n",
      "Epoch 54/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.3906 - mae: 19.3906\n",
      "Epoch 54: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1024.4189 - mae: 1024.4189\n",
      "Epoch 55/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 69.3662 - mae: 69.3662\n",
      "Epoch 55: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 752.2568 - mae: 752.2568\n",
      "Epoch 56/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.0334 - mae: 19.0334\n",
      "Epoch 56: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1013.0608 - mae: 1013.0608\n",
      "Epoch 57/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 68.7487 - mae: 68.7487\n",
      "Epoch 57: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 760.9850 - mae: 760.9850\n",
      "Epoch 58/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.1370 - mae: 19.1370\n",
      "Epoch 58: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1006.1865 - mae: 1006.1865\n",
      "Epoch 59/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 68.0690 - mae: 68.0690\n",
      "Epoch 59: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 735.7662 - mae: 735.7662\n",
      "Epoch 60/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.0467 - mae: 19.0467\n",
      "Epoch 60: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1010.1763 - mae: 1010.1763\n",
      "Epoch 61/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 68.4128 - mae: 68.4128\n",
      "Epoch 61: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 755.4656 - mae: 755.4656\n",
      "Epoch 62/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.9929 - mae: 18.9929\n",
      "Epoch 62: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 999.6706 - mae: 999.6706\n",
      "Epoch 63/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 67.6673 - mae: 67.6673\n",
      "Epoch 63: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 733.7869 - mae: 733.7869\n",
      "Epoch 64/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.9112 - mae: 18.9112\n",
      "Epoch 64: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 998.6803 - mae: 998.6803\n",
      "Epoch 65/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 67.7667 - mae: 67.7667\n",
      "Epoch 65: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 748.5806 - mae: 748.5806\n",
      "Epoch 66/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.8200 - mae: 18.8200\n",
      "Epoch 66: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 987.8564 - mae: 987.8564\n",
      "Epoch 67/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 66.6346 - mae: 66.6346\n",
      "Epoch 67: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 718.9401 - mae: 718.9401\n",
      "Epoch 68/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.0110 - mae: 19.0110\n",
      "Epoch 68: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1006.4783 - mae: 1006.4783\n",
      "Epoch 69/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 68.6096 - mae: 68.6096\n",
      "Epoch 69: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 766.4073 - mae: 766.4073\n",
      "Epoch 70/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.4031 - mae: 18.4031\n",
      "Epoch 70: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 960.7194 - mae: 960.7194\n",
      "Epoch 71/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 65.0763 - mae: 65.0763\n",
      "Epoch 71: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 704.9203 - mae: 704.9203\n",
      "Epoch 72/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.8317 - mae: 18.8317\n",
      "Epoch 72: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 982.5623 - mae: 982.5623\n",
      "Epoch 73/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 66.6035 - mae: 66.6035\n",
      "Epoch 73: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 735.9446 - mae: 735.9446\n",
      "Epoch 74/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.3224 - mae: 18.3224\n",
      "Epoch 74: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 960.8405 - mae: 960.8405\n",
      "Epoch 75/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 64.9707 - mae: 64.9707\n",
      "Epoch 75: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 703.9279 - mae: 703.9279\n",
      "Epoch 76/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.5027 - mae: 18.5027\n",
      "Epoch 76: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 965.2455 - mae: 965.2455\n",
      "Epoch 77/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 65.4125 - mae: 65.4125\n",
      "Epoch 77: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 729.4390 - mae: 729.4390\n",
      "Epoch 78/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.2770 - mae: 18.2770\n",
      "Epoch 78: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 938.5380 - mae: 938.5381\n",
      "Epoch 79/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 64.1119 - mae: 64.1119\n",
      "Epoch 79: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 694.2656 - mae: 694.2656\n",
      "Epoch 80/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.2598 - mae: 18.2598\n",
      "Epoch 80: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 943.1871 - mae: 943.1871\n",
      "Epoch 81/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 63.4432 - mae: 63.4432\n",
      "Epoch 81: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 701.3237 - mae: 701.3237\n",
      "Epoch 82/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.6280 - mae: 18.6280\n",
      "Epoch 82: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 953.4704 - mae: 953.4704\n",
      "Epoch 83/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 65.1374 - mae: 65.1374\n",
      "Epoch 83: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 706.7728 - mae: 706.7728\n",
      "Epoch 84/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.0281 - mae: 18.0281\n",
      "Epoch 84: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 924.3732 - mae: 924.3732\n",
      "Epoch 85/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 62.2877 - mae: 62.2877\n",
      "Epoch 85: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 690.2297 - mae: 690.2297\n",
      "Epoch 86/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.5982 - mae: 18.5982\n",
      "Epoch 86: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 937.5020 - mae: 937.5020\n",
      "Epoch 87/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 63.7351 - mae: 63.7351\n",
      "Epoch 87: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 681.0793 - mae: 681.0793\n",
      "Epoch 88/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.1924 - mae: 18.1924\n",
      "Epoch 88: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 944.3036 - mae: 944.3036\n",
      "Epoch 89/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 63.6779 - mae: 63.6779\n",
      "Epoch 89: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 712.3848 - mae: 712.3848\n",
      "Epoch 90/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.2489 - mae: 18.2489\n",
      "Epoch 90: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 919.9313 - mae: 919.9313\n",
      "Epoch 91/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 63.0616 - mae: 63.0616\n",
      "Epoch 91: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 680.8220 - mae: 680.8220\n",
      "Epoch 92/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.0205 - mae: 18.0205\n",
      "Epoch 92: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 921.2733 - mae: 921.2733\n",
      "Epoch 93/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 61.8585 - mae: 61.8585\n",
      "Epoch 93: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 683.3663 - mae: 683.3663\n",
      "Epoch 94/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.5568 - mae: 18.5568\n",
      "Epoch 94: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 928.5004 - mae: 928.5004\n",
      "Epoch 95/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 63.3604 - mae: 63.3604\n",
      "Epoch 95: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 682.1017 - mae: 682.1017\n",
      "Epoch 96/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 17.9516 - mae: 17.9516\n",
      "Epoch 96: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 916.2749 - mae: 916.2749\n",
      "Epoch 97/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 61.5888 - mae: 61.5888\n",
      "Epoch 97: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 683.3220 - mae: 683.3220\n",
      "Epoch 98/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.4247 - mae: 18.4247\n",
      "Epoch 98: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 917.0201 - mae: 917.0201\n",
      "Epoch 99/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 62.5693 - mae: 62.5693\n",
      "Epoch 99: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 671.0714 - mae: 671.0714\n",
      "Epoch 100/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 17.9537 - mae: 17.9537\n",
      "Epoch 100: mae did not improve from 573.96106\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 917.1434 - mae: 917.1434\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(WINDOW_SIZE,))\n",
    "\n",
    "x = tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\")(inputs)\n",
    "\n",
    "x = tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\")(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(HORIZON,activation=\"linear\")(x)\n",
    "\n",
    "model2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model2.compile(\n",
    "    loss = tf.keras.losses.mae,\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"mae\"]\n",
    ")\n",
    "\n",
    "history = model2.fit(\n",
    "    data,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(\n",
    "        monitor=\"mae\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        save_freq=\"epoch\",\n",
    "        filepath=\"D:/Me-ScriptsnShit/TensorFlow/Time Series/\",\n",
    "        verbose=1\n",
    "        )]\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 936x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(13,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTO_FUTURE=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create function to make predictions into the future\n",
    "\n",
    "def make_future_forecasts(values, model, into_future, window_size=WINDOW_SIZE) -> list:\n",
    "    \"\"\"  \n",
    "    Make future forecasts into_future steps after values ends.\n",
    "\n",
    "    Returns future forecasts as a list of floats.\n",
    "    \"\"\"\n",
    "\n",
    "    # 2. Create an empty list for future forecasts/prepare data to forecast on \n",
    "\n",
    "    future_forecast = []\n",
    "    last_window = values[-WINDOW_SIZE:]\n",
    "\n",
    "    # 3. Make INTO_FUTURE number of predictions, altering the data which gets predicted on each\n",
    "\n",
    "    for _ in range(INTO_FUTURE):\n",
    "\n",
    "        # Predict on the last window then append it again, again, again (our model will eventually start to make forecasts on its own forecast)\n",
    "        future_pred = model.predict(tf.expand_dims(last_window,axis=0))\n",
    "        print(f\"Predicting on:n\\ {last_window} -> Prediction: {tf.squeeze(future_pred).numpy()}\\n\")\n",
    "\n",
    "        # Append predictions to future_forecast\n",
    "\n",
    "        future_forecast.append(tf.squeeze(future_pred).numpy())\n",
    "        \n",
    "        # Update last window with new pred and get WINDOW_SIZE most recent preds (model was trained on WINDOW_SIZE windows)\n",
    "\n",
    "        last_window = np.append(last_window, future_pred)[-WINDOW_SIZE:]\n",
    "\n",
    "  \n",
    "        \n",
    "    return future_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>Closing Price (USD)</th>\n",
       "      <th>24h Open (USD)</th>\n",
       "      <th>24h High (USD)</th>\n",
       "      <th>24h Low (USD)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>BTC</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>124.30466</td>\n",
       "      <td>124.75166</td>\n",
       "      <td>122.56349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>BTC</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>125.75850</td>\n",
       "      <td>123.63383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>BTC</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>125.66566</td>\n",
       "      <td>83.32833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>BTC</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>118.67500</td>\n",
       "      <td>107.05816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>BTC</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>121.93633</td>\n",
       "      <td>118.00566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Currency  Closing Price (USD)  24h Open (USD)  24h High (USD)  \\\n",
       "Date                                                                       \n",
       "2013-10-01      BTC            123.65499       124.30466       124.75166   \n",
       "2013-10-02      BTC            125.45500       123.65499       125.75850   \n",
       "2013-10-03      BTC            108.58483       125.45500       125.66566   \n",
       "2013-10-04      BTC            118.67466       108.58483       118.67500   \n",
       "2013-10-05      BTC            121.33866       118.67466       121.93633   \n",
       "\n",
       "            24h Low (USD)  \n",
       "Date                       \n",
       "2013-10-01      122.56349  \n",
       "2013-10-02      123.63383  \n",
       "2013-10-03       83.32833  \n",
       "2013-10-04      107.05816  \n",
       "2013-10-05      118.00566  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\",parse_dates=[\"Date\"],index_col=[\"Date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price\n",
       "Date                 \n",
       "2013-10-01  123.65499\n",
       "2013-10-02  125.45500\n",
       "2013-10-03  108.58483\n",
       "2013-10-04  118.67466\n",
       "2013-10-05  121.33866"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices = pd.DataFrame(df[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\":\"Price\"})\n",
    "bitcoin_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_prices[\"Price\"] = (bitcoin_prices[\"Price\"] - bitcoin_prices[\"Price\"].min()) / (bitcoin_prices[\"Price\"].max() - bitcoin_prices[\"Price\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>0.785214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-15</th>\n",
       "      <td>0.789461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-16</th>\n",
       "      <td>0.755509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-17</th>\n",
       "      <td>0.719439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18</th>\n",
       "      <td>0.680536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2787 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price\n",
       "Date                \n",
       "2013-10-01  0.000238\n",
       "2013-10-02  0.000267\n",
       "2013-10-03  0.000000\n",
       "2013-10-04  0.000160\n",
       "2013-10-05  0.000202\n",
       "...              ...\n",
       "2021-05-14  0.785214\n",
       "2021-05-15  0.789461\n",
       "2021-05-16  0.755509\n",
       "2021-05-17  0.719439\n",
       "2021-05-18  0.680536\n",
       "\n",
       "[2787 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 7\n",
    "HORIZON     = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>0.000238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-06</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-07</th>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-08</th>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-09</th>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-10</th>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price   Price+1   Price+2   Price+3   Price+4   Price+5  \\\n",
       "Date                                                                     \n",
       "2013-10-01  0.000238       NaN       NaN       NaN       NaN       NaN   \n",
       "2013-10-02  0.000267  0.000238       NaN       NaN       NaN       NaN   \n",
       "2013-10-03  0.000000  0.000267  0.000238       NaN       NaN       NaN   \n",
       "2013-10-04  0.000160  0.000000  0.000267  0.000238       NaN       NaN   \n",
       "2013-10-05  0.000202  0.000160  0.000000  0.000267  0.000238       NaN   \n",
       "2013-10-06  0.000191  0.000202  0.000160  0.000000  0.000267  0.000238   \n",
       "2013-10-07  0.000209  0.000191  0.000202  0.000160  0.000000  0.000267   \n",
       "2013-10-08  0.000228  0.000209  0.000191  0.000202  0.000160  0.000000   \n",
       "2013-10-09  0.000245  0.000228  0.000209  0.000191  0.000202  0.000160   \n",
       "2013-10-10  0.000275  0.000245  0.000228  0.000209  0.000191  0.000202   \n",
       "\n",
       "             Price+6   Price+7  \n",
       "Date                            \n",
       "2013-10-01       NaN       NaN  \n",
       "2013-10-02       NaN       NaN  \n",
       "2013-10-03       NaN       NaN  \n",
       "2013-10-04       NaN       NaN  \n",
       "2013-10-05       NaN       NaN  \n",
       "2013-10-06       NaN       NaN  \n",
       "2013-10-07  0.000238       NaN  \n",
       "2013-10-08  0.000267  0.000238  \n",
       "2013-10-09  0.000000  0.000267  \n",
       "2013-10-10  0.000160  0.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(WINDOW_SIZE):\n",
    "    bitcoin_prices[f\"Price+{i+1}\"] = bitcoin_prices[\"Price\"].shift(periods=i+1)\n",
    "\n",
    "bitcoin_prices.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bitcoin_prices.dropna().drop([\"Price\"],axis=1).to_numpy()\n",
    "y = bitcoin_prices.dropna()[\"Price\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf.data.Dataset.from_tensor_slices(X)\n",
    "labels   = tf.data.Dataset.from_tensor_slices(y)\n",
    "\n",
    "data = tf.data.Dataset.zip((features,labels))\n",
    "\n",
    "data = data.batch(1024).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.0295 - accuracy: 3.5971e-04\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0632 - mae: 0.0632 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0203 - mae: 0.0203 - accuracy: 3.5971e-04\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0679 - mae: 0.0679 - accuracy: 3.5971e-04\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0427 - mae: 0.0427 - accuracy: 3.5971e-04\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0358 - mae: 0.0358 - accuracy: 3.5971e-04\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0276 - mae: 0.0276 - accuracy: 3.5971e-04\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0398 - mae: 0.0398 - accuracy: 3.5971e-04\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0333 - mae: 0.0333 - accuracy: 3.5971e-04\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0215 - mae: 0.0215 - accuracy: 3.5971e-04\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0173 - mae: 0.0173 - accuracy: 3.5971e-04\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0303 - mae: 0.0303 - accuracy: 3.5971e-04\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.0197 - accuracy: 3.5971e-04\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0318 - mae: 0.0318 - accuracy: 3.5971e-04\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0253 - mae: 0.0253 - accuracy: 3.5971e-04\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0267 - mae: 0.0267 - accuracy: 3.5971e-04\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0230 - mae: 0.0230 - accuracy: 3.5971e-04\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0248 - mae: 0.0248 - accuracy: 3.5971e-04\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0188 - mae: 0.0188 - accuracy: 3.5971e-04\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0265 - mae: 0.0265 - accuracy: 3.5971e-04\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0183 - mae: 0.0183 - accuracy: 3.5971e-04\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0282 - mae: 0.0282 - accuracy: 3.5971e-04\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0209 - mae: 0.0209 - accuracy: 3.5971e-04\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0282 - mae: 0.0282 - accuracy: 3.5971e-04\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0247 - mae: 0.0247 - accuracy: 3.5971e-04\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0214 - mae: 0.0214 - accuracy: 3.5971e-04\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0167 - mae: 0.0167 - accuracy: 3.5971e-04\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0254 - mae: 0.0254 - accuracy: 3.5971e-04\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0165 - mae: 0.0165 - accuracy: 3.5971e-04\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0284 - mae: 0.0284 - accuracy: 3.5971e-04\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0214 - mae: 0.0214 - accuracy: 3.5971e-04\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0264 - mae: 0.0264 - accuracy: 3.5971e-04\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0223 - mae: 0.0223 - accuracy: 3.5971e-04\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0210 - mae: 0.0210 - accuracy: 3.5971e-04    \n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0160 - mae: 0.0160 - accuracy: 3.5971e-04\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0256 - mae: 0.0256 - accuracy: 3.5971e-04\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0174 - mae: 0.0174 - accuracy: 3.5971e-04\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0256 - mae: 0.0256 - accuracy: 3.5971e-04\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.0187 - accuracy: 3.5971e-04\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0257 - mae: 0.0257 - accuracy: 3.5971e-04    \n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0215 - mae: 0.0215 - accuracy: 3.5971e-04\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0213 - mae: 0.0213 - accuracy: 3.5971e-04\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0169 - mae: 0.0169 - accuracy: 3.5971e-04\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0229 - mae: 0.0229 - accuracy: 3.5971e-04    \n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0154 - mae: 0.0154 - accuracy: 3.5971e-04\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0255 - mae: 0.0255 - accuracy: 3.5971e-04\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.0187 - accuracy: 3.5971e-04\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0247 - mae: 0.0247 - accuracy: 3.5971e-04\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0206 - mae: 0.0206 - accuracy: 3.5971e-04\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 0.0204 - accuracy: 3.5971e-04\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0159 - mae: 0.0159 - accuracy: 3.5971e-04\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0227 - mae: 0.0227 - accuracy: 3.5971e-04\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0151 - mae: 0.0151 - accuracy: 3.5971e-04\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0252 - mae: 0.0252 - accuracy: 3.5971e-04\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0184 - mae: 0.0184 - accuracy: 3.5971e-04\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0241 - mae: 0.0241 - accuracy: 3.5971e-04\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0199 - mae: 0.0199 - accuracy: 3.5971e-04\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0201 - mae: 0.0201 - accuracy: 3.5971e-04    \n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0156 - mae: 0.0156 - accuracy: 3.5971e-04\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0223 - mae: 0.0223 - accuracy: 3.5971e-04    \n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0151 - mae: 0.0151 - accuracy: 3.5971e-04\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0240 - mae: 0.0240 - accuracy: 3.5971e-04\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0176 - mae: 0.0176 - accuracy: 3.5971e-04\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0234 - mae: 0.0234 - accuracy: 3.5971e-04    \n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0193 - mae: 0.0193 - accuracy: 3.5971e-04\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0201 - mae: 0.0201 - accuracy: 3.5971e-04    \n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0156 - accuracy: 3.5971e-04\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0215 - mae: 0.0215 - accuracy: 3.5971e-04    \n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0144 - mae: 0.0144 - accuracy: 3.5971e-04\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0237 - mae: 0.0237 - accuracy: 3.5971e-04\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0171 - mae: 0.0171 - accuracy: 3.5971e-04\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0232 - mae: 0.0232 - accuracy: 3.5971e-04    \n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0192 - mae: 0.0192 - accuracy: 3.5971e-04\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0193 - mae: 0.0193 - accuracy: 3.5971e-04    \n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0151 - mae: 0.0151 - accuracy: 3.5971e-04\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0212 - mae: 0.0212 - accuracy: 3.5971e-04    \n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0142 - mae: 0.0142 - accuracy: 3.5971e-04\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0231 - mae: 0.0231 - accuracy: 3.5971e-04\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0169 - mae: 0.0169 - accuracy: 3.5971e-04\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0223 - mae: 0.0223 - accuracy: 3.5971e-04    \n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0182 - mae: 0.0182 - accuracy: 3.5971e-04\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0191 - mae: 0.0191 - accuracy: 3.5971e-04    \n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0147 - accuracy: 3.5971e-04\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0207 - mae: 0.0207 - accuracy: 3.5971e-04    \n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0142 - mae: 0.0142 - accuracy: 3.5971e-04\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0219 - mae: 0.0219 - accuracy: 3.5971e-04\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0157 - mae: 0.0157 - accuracy: 3.5971e-04\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0219 - mae: 0.0219 - accuracy: 3.5971e-04    \n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0179 - mae: 0.0179 - accuracy: 3.5971e-04\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.0186 - accuracy: 3.5971e-04    \n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0145 - mae: 0.0145 - accuracy: 3.5971e-04\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0199 - mae: 0.0199 - accuracy: 3.5971e-04    \n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.0136 - accuracy: 3.5971e-04\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0211 - mae: 0.0211 - accuracy: 3.5971e-04\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0147 - mae: 0.0147 - accuracy: 3.5971e-04\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0220 - mae: 0.0220 - accuracy: 3.5971e-04    \n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.0180 - accuracy: 3.5971e-04\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0177 - mae: 0.0177 - accuracy: 3.5971e-04    \n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0140 - mae: 0.0140 - accuracy: 3.5971e-04\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0190 - mae: 0.0190 - accuracy: 3.5971e-04    \n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(WINDOW_SIZE,),name=\"input_layer\")\n",
    "\n",
    "x = tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\",name=\"Dense_1\")(inputs)\n",
    "\n",
    "x = tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\",name=\"Dense_2\")(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(HORIZON,activation=\"linear\",name=\"output_layer\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3\")\n",
    "\n",
    "model_3.compile(\n",
    "    loss = tf.keras.losses.mae,\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"mae\",\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_3 = model_3.fit(\n",
    "    data,\n",
    "    epochs=100,\n",
    "    verbose=1\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0037 - accuracy: 3.5971e-04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00373723148368299, 0.00373723148368299, 0.0003597122267819941]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00035971"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.5971e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1586 - mae: 0.1586\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1117 - mae: 0.1117\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0951 - mae: 0.0951\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0838 - mae: 0.0838\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0769 - mae: 0.0769\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0743 - mae: 0.0743\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0751 - mae: 0.0751\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0752 - mae: 0.0752\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0724 - mae: 0.0724\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0603 - mae: 0.0603\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0540 - mae: 0.0540\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0482 - mae: 0.0482\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0427 - mae: 0.0427\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0373 - mae: 0.0373\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0322 - mae: 0.0322\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0275 - mae: 0.0275\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0231 - mae: 0.0231\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0147 - mae: 0.0147\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0136\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0145\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.0149\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0146\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0143\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0145\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0145\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0143\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0141\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0135\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0124 - mae: 0.0124\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0123\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.0122\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0121\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0120 - mae: 0.0120\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0119\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215adfd6620>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = model2\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(WINDOW_SIZE,))\n",
    "\n",
    "x = base_model(inputs,training=False)\n",
    "\n",
    "x = tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\")(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(HORIZON,activation=\"linear\")(x)\n",
    "\n",
    "model_4 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_4.compile(\n",
    "    loss = \"mae\",\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"mae\"]\n",
    ")\n",
    "\n",
    "model_4.fit(\n",
    "    data,\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>Closing Price (USD)</th>\n",
       "      <th>24h Open (USD)</th>\n",
       "      <th>24h High (USD)</th>\n",
       "      <th>24h Low (USD)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>BTC</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>124.30466</td>\n",
       "      <td>124.75166</td>\n",
       "      <td>122.56349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>BTC</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>125.75850</td>\n",
       "      <td>123.63383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>BTC</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>125.66566</td>\n",
       "      <td>83.32833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>BTC</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>118.67500</td>\n",
       "      <td>107.05816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>BTC</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>121.93633</td>\n",
       "      <td>118.00566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Currency  Closing Price (USD)  24h Open (USD)  24h High (USD)  \\\n",
       "Date                                                                       \n",
       "2013-10-01      BTC            123.65499       124.30466       124.75166   \n",
       "2013-10-02      BTC            125.45500       123.65499       125.75850   \n",
       "2013-10-03      BTC            108.58483       125.45500       125.66566   \n",
       "2013-10-04      BTC            118.67466       108.58483       118.67500   \n",
       "2013-10-05      BTC            121.33866       118.67466       121.93633   \n",
       "\n",
       "            24h Low (USD)  \n",
       "Date                       \n",
       "2013-10-01      122.56349  \n",
       "2013-10-02      123.63383  \n",
       "2013-10-03       83.32833  \n",
       "2013-10-04      107.05816  \n",
       "2013-10-05      118.00566  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\",parse_dates=[\"Date\"],index_col=[\"Date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.654990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.584830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.674660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.338660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>49764.132082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-15</th>\n",
       "      <td>50032.693137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-16</th>\n",
       "      <td>47885.625255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-17</th>\n",
       "      <td>45604.615754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18</th>\n",
       "      <td>43144.471291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2787 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Price\n",
       "Date                    \n",
       "2013-10-01    123.654990\n",
       "2013-10-02    125.455000\n",
       "2013-10-03    108.584830\n",
       "2013-10-04    118.674660\n",
       "2013-10-05    121.338660\n",
       "...                  ...\n",
       "2021-05-14  49764.132082\n",
       "2021-05-15  50032.693137\n",
       "2021-05-16  47885.625255\n",
       "2021-05-17  45604.615754\n",
       "2021-05-18  43144.471291\n",
       "\n",
       "[2787 rows x 1 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices = pd.DataFrame(df[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\":\"Price\"})\n",
    "bitcoin_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 7\n",
    "HORIZON     = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.654990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.455000</td>\n",
       "      <td>123.654990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.584830</td>\n",
       "      <td>125.455000</td>\n",
       "      <td>123.654990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.674660</td>\n",
       "      <td>108.584830</td>\n",
       "      <td>125.455000</td>\n",
       "      <td>123.654990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.338660</td>\n",
       "      <td>118.674660</td>\n",
       "      <td>108.584830</td>\n",
       "      <td>125.455000</td>\n",
       "      <td>123.654990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "      <td>58102.191426</td>\n",
       "      <td>58788.209679</td>\n",
       "      <td>57107.120672</td>\n",
       "      <td>56583.849879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-15</th>\n",
       "      <td>50032.693137</td>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "      <td>58102.191426</td>\n",
       "      <td>58788.209679</td>\n",
       "      <td>57107.120672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-16</th>\n",
       "      <td>47885.625255</td>\n",
       "      <td>50032.693137</td>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "      <td>58102.191426</td>\n",
       "      <td>58788.209679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-17</th>\n",
       "      <td>45604.615754</td>\n",
       "      <td>47885.625255</td>\n",
       "      <td>50032.693137</td>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "      <td>58102.191426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18</th>\n",
       "      <td>43144.471291</td>\n",
       "      <td>45604.615754</td>\n",
       "      <td>47885.625255</td>\n",
       "      <td>50032.693137</td>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2787 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Price       Price+1       Price+2       Price+3  \\\n",
       "Date                                                                 \n",
       "2013-10-01    123.654990           NaN           NaN           NaN   \n",
       "2013-10-02    125.455000    123.654990           NaN           NaN   \n",
       "2013-10-03    108.584830    125.455000    123.654990           NaN   \n",
       "2013-10-04    118.674660    108.584830    125.455000    123.654990   \n",
       "2013-10-05    121.338660    118.674660    108.584830    125.455000   \n",
       "...                  ...           ...           ...           ...   \n",
       "2021-05-14  49764.132082  52147.821187  56573.555472  55715.546651   \n",
       "2021-05-15  50032.693137  49764.132082  52147.821187  56573.555472   \n",
       "2021-05-16  47885.625255  50032.693137  49764.132082  52147.821187   \n",
       "2021-05-17  45604.615754  47885.625255  50032.693137  49764.132082   \n",
       "2021-05-18  43144.471291  45604.615754  47885.625255  50032.693137   \n",
       "\n",
       "                 Price+4       Price+5       Price+6       Price+7  \n",
       "Date                                                                \n",
       "2013-10-01           NaN           NaN           NaN           NaN  \n",
       "2013-10-02           NaN           NaN           NaN           NaN  \n",
       "2013-10-03           NaN           NaN           NaN           NaN  \n",
       "2013-10-04           NaN           NaN           NaN           NaN  \n",
       "2013-10-05    123.654990           NaN           NaN           NaN  \n",
       "...                  ...           ...           ...           ...  \n",
       "2021-05-14  58102.191426  58788.209679  57107.120672  56583.849879  \n",
       "2021-05-15  55715.546651  58102.191426  58788.209679  57107.120672  \n",
       "2021-05-16  56573.555472  55715.546651  58102.191426  58788.209679  \n",
       "2021-05-17  52147.821187  56573.555472  55715.546651  58102.191426  \n",
       "2021-05-18  49764.132082  52147.821187  56573.555472  55715.546651  \n",
       "\n",
       "[2787 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(WINDOW_SIZE):\n",
    "    bitcoin_prices[f\"Price+{i+1}\"] = bitcoin_prices[\"Price\"].shift(periods=i+1)\n",
    "\n",
    "bitcoin_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bitcoin_prices.dropna().drop(\"Price\",axis=1).to_numpy()\n",
    "y = bitcoin_prices.dropna()[\"Price\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.data.Dataset.from_tensor_slices(X)\n",
    "labels   = tf.data.Dataset.from_tensor_slices(y)\n",
    "\n",
    "data = tf.data.Dataset.zip((features,labels))\n",
    "\n",
    "data = data.batch(1024).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [[   40.912155]\n [   38.015602]\n [   24.364288]\n ...\n [21425.844   ]\n [19749.918   ]\n [20092.      ]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Me-ScriptsnShit\\TensorFlow\\Time Series\\TS-Exercise.ipynb Hücre 48\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m128\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m,kernel_initializer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhe_normal\u001b[39m\u001b[39m\"\u001b[39m)(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(HORIZON,activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m)(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model_5 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mModel(inputs, outputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model_5\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     metrics \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model_5\u001b[39m.\u001b[39mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/Time%20Series/TS-Exercise.ipynb#Y103sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py:148\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m([functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    146\u001b[0m               \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)]):\n\u001b[0;32m    147\u001b[0m     inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(inputs, outputs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py:186\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    183\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m'\u001b[39m\u001b[39m_keras_history\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs):\n\u001b[0;32m    184\u001b[0m     base_layer_utils\u001b[39m.\u001b[39mcreate_keras_history(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nested_outputs)\n\u001b[1;32m--> 186\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_graph_inputs_and_outputs()\n\u001b[0;32m    188\u001b[0m \u001b[39m# A Network does not create weights of its own, thus it is already\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m# built.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py:740\u001b[0m, in \u001b[0;36mFunctional._validate_graph_inputs_and_outputs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39m_keras_history\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    739\u001b[0m   cls_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m--> 740\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOutput tensors of a \u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m model must be \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    741\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mthe output of a TensorFlow `Layer` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    742\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(thus holding past layer metadata). Found: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [[   40.912155]\n [   38.015602]\n [   24.364288]\n ...\n [21425.844   ]\n [19749.918   ]\n [20092.      ]]"
     ]
    }
   ],
   "source": [
    "base_model = model_3\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(WINDOW_SIZE,))\n",
    "\n",
    "x = base_model(inputs,training=False)\n",
    "x = tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\")(X)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(HORIZON,activation=\"linear\")(x)\n",
    "\n",
    "\n",
    "model_5 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_5.compile(\n",
    "    loss = \"mae\",\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"mae\"]\n",
    ")\n",
    "\n",
    "model_5.fit(\n",
    "    data,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e15f063e7e42353c9736ef962fc7c67de892cf5c7bb88439fb47c3c850fa6062"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
